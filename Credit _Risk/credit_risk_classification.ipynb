{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file from the Resources folder into a Pandas DataFrame\n",
    "df = pd.read_csv(\"Resources/lending_data.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# Review the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loan_status.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs=df.corr()\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corrs, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(corrs.loan_status).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['loan_size', 'interest_rate', 'borrower_income', 'debt_to_income',\n",
    "       'num_of_accounts', 'derogatory_marks', 'total_debt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE the NUMERIC Features FIRST\n",
    "\n",
    "# subset\n",
    "df_sub = df.loc[:, features]\n",
    "\n",
    "# initialize\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit\n",
    "scaler.fit(df_sub)\n",
    "\n",
    "# predict/transform\n",
    "scaled_data = scaler.transform(df_sub)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=features)\n",
    "\n",
    "df_scaled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the data\n",
    "X = df_scaled\n",
    "y = df.loan_status\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) # stratify=True maintains target class percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Classification\n",
    "def doClassification(model, X_train, X_test, y_train, y_test):\n",
    "    # Step 3: Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 4: Evaluate the model\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    train_proba = model.predict_proba(X_train)[:, 1]\n",
    "    test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Generate metrics TRAIN\n",
    "    train_cf = confusion_matrix(y_train, train_preds)\n",
    "    train_cr = classification_report(y_train, train_preds)\n",
    "    train_auc = roc_auc_score(y_train, train_proba)\n",
    "    \n",
    "    train_results = f\"\"\"TRAIN METRICS\n",
    "    Confusion Matrix: {train_cf}\n",
    "    AUC: {train_auc}\n",
    "    {train_cr}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(train_results)\n",
    "\n",
    "    # Generate metrics TEST\n",
    "    test_cf = confusion_matrix(y_test, test_preds)\n",
    "    test_cr = classification_report(y_test, test_preds)\n",
    "    test_auc = roc_auc_score(y_test, test_proba)\n",
    "    \n",
    "    test_results = f\"\"\"TEST METRICS\n",
    "    Confusion Matrix: {test_cf}\n",
    "    AUC: {test_auc}\n",
    "    {test_cr}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(test_results)\n",
    "\n",
    "    # VISUALIZE TEST RESULTS\n",
    "    fpr, tpr, _ = roc_curve(y_test.values, test_proba)\n",
    "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "    roc_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Step 2: Init the Model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Do Machine Learning\n",
    "doClassification(lr, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Init the Model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Do Machine Learning\n",
    "doClassification(dt, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Init the Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Do Machine Learning\n",
    "doClassification(rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intiate the model\n",
    "svc= SVC(probability =True)\n",
    "\n",
    "#machine learning\n",
    "doClassification(svc, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Init the Model\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "# Do Machine Learning\n",
    "doClassification(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Init the Model\n",
    "et = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Do Machine Learning\n",
    "doClassification(et, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Init the Model\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Do Machine Learning\n",
    "doClassification(ada, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb= GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "#machine learning\n",
    "doClassification(gb, X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the model\n",
    "xgb=XGBClassifier(_random_state=42)\n",
    "#machine learning\n",
    "doClassification(xgb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the model\n",
    "lgbm=LGBMClassifier(_random_state=42, verbose= -1)\n",
    "#machine learning\n",
    "doClassification(lgbm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Step 2: Init the Model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Do Machine Learning\n",
    "doClassification(lr, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(list(zip(X.columns, ada.feature_importances_)), columns=[\"Feature\", \"Importance\"])\n",
    "fi.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(list(zip(X.columns, xgb.feature_importances_)), columns=[\"Feature\", \"Importance\"])\n",
    "fi.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(list(zip(X.columns, lgbm.feature_importances_)), columns=[\"Feature\", \"Importance\"])\n",
    "fi.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "\n",
    "# Separate the y variable, the labels\n",
    "y = df['loan_status']\n",
    "# Separate the X variable, the features\n",
    "X = df.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the y variable Series\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the X variable DataFrame\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_learn module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "logistic_regression_model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "\n",
    "# Fit the model using training data\n",
    "lr_model = logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the testing data\n",
    "test_predictions = logistic_regression_model.predict(X_test)\n",
    "pd.DataFrame({'Predictions': test_predictions, 'Actual': y_test})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "cf_test_matrix = confusion_matrix(y_test, test_predictions)\n",
    "cf_test_matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report for the model\n",
    "testing_report = classification_report(y_test, test_predictions)\n",
    "print(testing_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** The logistic regression model was 95% accurate at predicting the healthy vs high-risk loan labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have sever imbalance, which i thought would affect model performance\n",
    "# low size of the positive soan_status class\n",
    "# logistic regression looks really good. \n",
    "# SVC model is really good -- this is likely because of the linear relationships complex math model\n",
    "# Knn model is also good similar people are likely to default together\n",
    "# Random forest/extratrees/decision tree they all seem to be finding patterns int he non=default class and missing patterns in the positive class\n",
    "# likely due to the small sample.\n",
    "# Trees are very dependent on sample size\n",
    "# ADA looks good \n",
    "# Boosted trees alos look really good, so they see, to have minimize the nodefault class patterns when predicting positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
